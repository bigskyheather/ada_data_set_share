{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Share Orangetheory  & Peloton\n",
    "\n",
    "This notebook includes the code that scrapes Twitter data from two fitness companies.\n",
    "\n",
    "It first scrapes both accounts for follower information and then, scrapes for tweets using hashtags."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import tweepy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Authenticate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# API keys in a .py file called API_keys.py\n",
    "from API_keys import api_key, api_key_secret, access_token, access_token_secret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Authenticate the Tweepy API\n",
    "auth = tweepy.OAuthHandler(api_key,api_key_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "api = tweepy.API(auth,wait_on_rate_limit=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grab Follower Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a list of handles\n",
    "handles = ['orangetheory','onepeloton']\n",
    "\n",
    "\n",
    "# This will iterate through each Twitter handle that we're collecting from\n",
    "for screen_name in handles:\n",
    "    \n",
    "    # Tells Tweepy we want information on the handle we're collecting from\n",
    "    # The next line specifies which information we want, which in this case is the number of followers \n",
    "    user = api.get_user(screen_name=screen_name) \n",
    "    followers_count = user.followers_count\n",
    "\n",
    "    # Let's see roughly how long it will take to grab all the follower IDs. \n",
    "    print(f'''\n",
    "    @{screen_name} has {followers_count} followers. \n",
    "    That will take roughly {followers_count/(5000*60):.0f} hours and {followers_count/(5000):.2f} minutes\n",
    "    ''')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# This creates a dictionary containing a list for each Twitter handle we'll be grabbing follower IDs from\n",
    "id_dict = {'orangetheory' : [],\n",
    "           'onepeloton' : []}\n",
    "\n",
    "# Grabs the time when we start making requests to the API\n",
    "start_time = datetime.datetime.now()\n",
    "\n",
    "# .keys() allows us to iterate through each key in the dictionary\n",
    "for handle in id_dict.keys():\n",
    "    \n",
    "    # Each page contains 5,000 records, so since we know there are much more than 5,000 followers for both\n",
    "    # we must iterate through each of the pages in order to get all follower IDs\n",
    "    # To grab the follower IDs, we will be using followers_ids\n",
    "    for page in tweepy.Cursor(api.get_follower_ids,\n",
    "                              # This is how we will get around the issue of not being able to grab all ids at once\n",
    "                              # Once the rate limit is hit, we will be notified that we must wait 15 mins (900 secs)\n",
    "                              wait_on_rate_limit=True, wait_on_rate_limit_notify=True, compression=True,\n",
    "                              screen_name=handle).pages():\n",
    "\n",
    "        # The page variable comes back as a list, so we have to use .extend rather than .append\n",
    "        id_dict[handle].extend(page)\n",
    "        \n",
    "\n",
    "# Let's see how long it took to grab all follower IDs\n",
    "end_time = datetime.datetime.now()\n",
    "elapsed_time = end_time - start_time\n",
    "print(elapsed_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Check out user IDs\n",
    "id_dict['orangetheory'][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check out user IDs\n",
    "id_dict['onepeloton'][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@orangetheory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#ID's are numbers and are are different from handles. To see the twitter handles we gathered, we'll have to use the screen_name feature.\n",
    "\n",
    "users = id_dict['orangetheory'][:10]\n",
    "for name in users:\n",
    "    \n",
    "    user = api.get_user(user_id=name)\n",
    "    print(user.screen_name)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@onepeloton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "users = id_dict['onepeloton'][:10]\n",
    "\n",
    "for name in users:\n",
    "    \n",
    "    user = api.get_user(user_id=name)\n",
    "    print(user.screen_name)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grab descriptions based on the followers IDs\n",
    "The code inside this function comes from Brenden Connors and has been updated to refelct API changes 10/2021\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will quickly grab information about each follower.\n",
    "def get_screen_names(list_of_ids, list_for_screen_names):\n",
    "    start=0 #we have feed the API 100 ID's at a time, this will iterate through them\n",
    "    end=0\n",
    "    followers=[]\n",
    "    while end-1 <= len(list_of_ids): #quit when we get past the end of our list\n",
    "        end += 100 #update the end of our slice\n",
    "        if end <= len(list_of_ids): #split into if else statement to slice correctly\n",
    "            try:\n",
    "                followers_temp = api.lookup_users(user_id = list_of_ids[start:end])    # Added in user_id\n",
    "            except TweepError as err: \n",
    "                if err.code == 103: #if we get a rate limit error, go to sleep\n",
    "                    print('sleeping, 900 seconds')\n",
    "                    time.sleep(900)\n",
    "        else:\n",
    "            try:\n",
    "                followers_temp = api.lookup_users(user_id = list_of_ids[start:])     #Added in user_id  object\n",
    "            except tweepy.TweepError as err:\n",
    "                if err.code == 103:\n",
    "                    print('sleeping, 900 seconds')\n",
    "                    time.sleep(900)\n",
    "        followers.extend(followers_temp)\n",
    "        start = end #update our starting slice index for next loop\n",
    "    list_for_screen_names.extend(followers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's put the function to use and make a new dictionary holding all user information\n",
    "user_dict = {'orangetheory': [],\n",
    "                    'onepeloton' : []}\n",
    "\n",
    "for handle in user_dict.keys():\n",
    "    \n",
    "    \n",
    "    get_screen_names(id_dict[handle],user_dict[handle])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function grabs all objects tied to a public Twitter account. If we take a look at the first follower, it'll look ugly. It is helpful to look through the output and see what objects you want, however. Let's just grab the screen_name and description for now, and write it to a .txt file. Since we have all the data stored in a dictionary, there won't be a wait time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#user_dict['orangetheory'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#user_dict['onepeloton'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = ['screen_name','description']\n",
    "\n",
    "for team in user_dict.keys():\n",
    "\n",
    "    # Descriptions with emoji or non-Roman letters can cause trouble. Encoding your .txt file in utf-8 will help\n",
    "    with open(f'{team}_followers.txt','w', encoding='utf-8') as out_file:\n",
    "        out_file.write('\\t'.join(headers) + '\\n')\n",
    "\n",
    "        for idx, user in enumerate(user_dict[team]):\n",
    "            \n",
    "            # For accounts set to private, we won't be able to get the description unless we follow them\n",
    "            # Putting in a try/except statement, we can get around this issue.\n",
    "            description = str(user.description).replace('\\t',' ').replace('\\n',' ')\n",
    "            outline = [user.screen_name, description]\n",
    "\n",
    "            out_file.write('\\t'.join([str(item) for item in outline]) + '\\n')\n",
    "              \n",
    "            #if idx == 100:\n",
    "               # break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grabbing Tweets with #Orangetheory\n",
    "Tweets were pulled 11/6/21"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### orangetheory hashtag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Note: the search API only goes back 7 days\n",
    "date_start = datetime.date.today()\n",
    "date_end = date_start - datetime.timedelta(days=2)\n",
    "\n",
    "search_words = f'#orangetheory since:{date_end} until:{date_start} -filter:retweets'\n",
    "\n",
    "# Notice the differences between searching tweets and users. \n",
    "for idx, item in enumerate(tweepy.Cursor(api.search_tweets, \n",
    "                                         q = search_words,\n",
    "                                         since= date_end,\n",
    "                                         tweet_mode='extended',# tweet_mode is defaulted to short, which only holds the first 140 characters of a Tweet.\n",
    "                                         lang='en').items()):\n",
    "    \n",
    "    # There's all sort of information you can get from Tweets\n",
    "    # Find more tweet objects here: https://developer.twitter.com/en/docs/twitter-api/v1/data-dictionary/overview/tweet-object\n",
    "    print(item.user.screen_name)\n",
    "    print(item.created_at)\n",
    "    print(item.full_text)\n",
    "    print('-'*40)\n",
    "    \n",
    "    #if idx == 1000:\n",
    "       # break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_words = '#orangetheory -filter:retweets'\n",
    "\n",
    "\n",
    "tweets_all = tweepy.Cursor(api.search_tweets,\n",
    "                   tweet_mode='extended',\n",
    "                   q=search_words,\n",
    "                   lang='en').items()\n",
    "\n",
    "# Put all the Tweet objects for a single Tweet into a tuple, and put all those into a list\n",
    "tweets = [(tweet.full_text,tweet.created_at,tweet.user.screen_name) for tweet in tweets_all]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#tweets[:2000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(tweets) \n",
    "    \n",
    "# saving the dataframe \n",
    "df.to_csv('orangetheory_hashtag.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### OTF hashtag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: the search API only goes back 7 days\n",
    "date_start = datetime.date.today()\n",
    "date_end = date_start - datetime.timedelta(days=2)\n",
    "\n",
    "search_words = f'#otf since:{date_end} until:{date_start} -filter:retweets'\n",
    "\n",
    "# Notice the differences between searching tweets and users. \n",
    "for idx, item in enumerate(tweepy.Cursor(api.search_tweets, \n",
    "                                         q = search_words,\n",
    "                                         since= date_end,\n",
    "                                         tweet_mode='extended',# tweet_mode is defaulted to short, which only holds the first 140 characters of a Tweet.\n",
    "                                         lang='en').items()):\n",
    "    \n",
    "    # There's all sort of information you can get from Tweets\n",
    "    # Find more tweet objects here: https://developer.twitter.com/en/docs/twitter-api/v1/data-dictionary/overview/tweet-object\n",
    "    print(item.user.screen_name)\n",
    "    print(item.created_at)\n",
    "    print(item.full_text)\n",
    "    print('-'*40)\n",
    "    \n",
    "    #if idx == 1000:\n",
    "       # break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_words = '#otf -filter:retweets'\n",
    "\n",
    "\n",
    "tweets_all = tweepy.Cursor(api.search_tweets,\n",
    "                   tweet_mode='extended',\n",
    "                   q=search_words,\n",
    "                   lang='en').items()\n",
    "\n",
    "# Put all the Tweet objects for a single Tweet into a tuple, and put all those into a list\n",
    "tweets = [(tweet.full_text,tweet.created_at,tweet.user.screen_name) for tweet in tweets_all]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(tweets) \n",
    "    \n",
    "# saving the dataframe \n",
    "df.to_csv('OTF_hashtag.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grabbing Tweets with #peleton\n",
    "Tweets were pulled 11/6/21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: the search API only goes back 7 days\n",
    "date_start = datetime.date.today()\n",
    "date_end = date_start - datetime.timedelta(days=2)\n",
    "\n",
    "search_words = f'#peloton since:{date_end} until:{date_start} -filter:retweets'\n",
    "\n",
    "# Notice the differences between searching tweets and users. \n",
    "for idx, item in enumerate(tweepy.Cursor(api.search_tweets, \n",
    "                                         q = search_words,\n",
    "                                         since= date_end,\n",
    "                                         tweet_mode='extended',# tweet_mode is defaulted to short, which only holds the first 140 characters of a Tweet.\n",
    "                                         lang='en').items()):\n",
    "    \n",
    "    print(item.user.screen_name)\n",
    "    print(item.created_at)\n",
    "    print(item.full_text)\n",
    "    print('-'*40)\n",
    "    \n",
    "    #if idx == 1000:\n",
    "       # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_words = '#peloton -filter:retweets'\n",
    "\n",
    "\n",
    "tweets_all = tweepy.Cursor(api.search_tweets,\n",
    "                   tweet_mode='extended',\n",
    "                   q=search_words,\n",
    "                   lang='en').items()\n",
    "\n",
    "# Put all the Tweet objects for a single Tweet into a tuple, and put all those into a list\n",
    "tweets = [(tweet.full_text,tweet.created_at,tweet.user.screen_name) for tweet in tweets_all]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(tweets) \n",
    "    \n",
    "# saving the dataframe \n",
    "df.to_csv('peloton_hashtag.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Follower & Hashtag Information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Orangetheory Followers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make df of OTF followers\n",
    "columns = [\"screen_name\", \"description\"]\n",
    "otf_followers = pd.read_csv('orangetheory_followers.txt', names=columns,sep='\\t', lineterminator='\\n')\n",
    "otf_followers = otf_followers.iloc[1: , :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(58260, 2)\n"
     ]
    }
   ],
   "source": [
    "# check df shape/size\n",
    "print(otf_followers.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>screen_name</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hingtox</td>\n",
       "      <td>tattoo collector\\r</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>alejandrthkmil1</td>\n",
       "      <td>Hades\\r</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>beverlgiyodet</td>\n",
       "      <td>I'm pretty boring and not really social lol I ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>omcojrex</td>\n",
       "      <td>Soundcloud rapper\\r</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>AarinRmorroy</td>\n",
       "      <td>Follow my Twitter @AynniaG\\r</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       screen_name                                        description\n",
       "1          hingtox                                 tattoo collector\\r\n",
       "2  alejandrthkmil1                                            Hades\\r\n",
       "3    beverlgiyodet  I'm pretty boring and not really social lol I ...\n",
       "4         omcojrex                                Soundcloud rapper\\r\n",
       "5     AarinRmorroy                       Follow my Twitter @AynniaG\\r"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check df head\n",
    "otf_followers.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Orangetheory Hashtags\n",
    "Since text pulled from #orangetheory is small, I also included #otf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#oragngetheory dataframe & stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\"tweet\", \"datetime\", \"screenname\"]\n",
    "orangetheory_hash = pd.read_csv('orangetheory_hashtag.csv', names=columns, sep=',')\n",
    "orangetheory_hash = orangetheory_hash.iloc[1: , :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21, 3)\n"
     ]
    }
   ],
   "source": [
    "# check df size / shape\n",
    "print(orangetheory_hash.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>datetime</th>\n",
       "      <th>screenname</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>Orangetheory takes over the Komets game! #oran...</td>\n",
       "      <td>2021-11-06 01:08:16+00:00</td>\n",
       "      <td>KAILEYMSHERMAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>We are excited to announce the promotion of Fr...</td>\n",
       "      <td>2021-11-05 14:09:09+00:00</td>\n",
       "      <td>KianCapital</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.0</th>\n",
       "      <td>The best Monday of 2021 is right around the \\r...</td>\n",
       "      <td>2021-11-05 13:17:26+00:00</td>\n",
       "      <td>OTFKempsCorner</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.0</th>\n",
       "      <td>One month (only 9 workouts) with @orangetheory...</td>\n",
       "      <td>2021-11-05 02:12:11+00:00</td>\n",
       "      <td>taterbennett</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4.0</th>\n",
       "      <td>When you can literally WORK towards your fitne...</td>\n",
       "      <td>2021-11-04 18:21:33+00:00</td>\n",
       "      <td>CB_Radio82</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 tweet  \\\n",
       "0.0  Orangetheory takes over the Komets game! #oran...   \n",
       "1.0  We are excited to announce the promotion of Fr...   \n",
       "2.0  The best Monday of 2021 is right around the \\r...   \n",
       "3.0  One month (only 9 workouts) with @orangetheory...   \n",
       "4.0  When you can literally WORK towards your fitne...   \n",
       "\n",
       "                      datetime      screenname  \n",
       "0.0  2021-11-06 01:08:16+00:00  KAILEYMSHERMAN  \n",
       "1.0  2021-11-05 14:09:09+00:00     KianCapital  \n",
       "2.0  2021-11-05 13:17:26+00:00  OTFKempsCorner  \n",
       "3.0  2021-11-05 02:12:11+00:00    taterbennett  \n",
       "4.0  2021-11-04 18:21:33+00:00      CB_Radio82  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check df head\n",
    "orangetheory_hash.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#otf dataframe & stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\"tweet\", \"datetime\", \"screenname\"]\n",
    "otf_hash = pd.read_csv('otf_hashtag.csv', names=columns, sep=',')\n",
    "otf_hash = otf_hash.iloc[1: , :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(230, 3)\n"
     ]
    }
   ],
   "source": [
    "# check size / shape\n",
    "print(otf_hash.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>datetime</th>\n",
       "      <th>screenname</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>Orangetheory takes over the Komets game! #oran...</td>\n",
       "      <td>2021-11-06 01:08:16+00:00</td>\n",
       "      <td>KAILEYMSHERMAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>We are excited to announce the promotion of Fr...</td>\n",
       "      <td>2021-11-05 14:09:09+00:00</td>\n",
       "      <td>KianCapital</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.0</th>\n",
       "      <td>The best Monday of 2021 is right around the \\r...</td>\n",
       "      <td>2021-11-05 13:17:26+00:00</td>\n",
       "      <td>OTFKempsCorner</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.0</th>\n",
       "      <td>One month (only 9 workouts) with @orangetheory...</td>\n",
       "      <td>2021-11-05 02:12:11+00:00</td>\n",
       "      <td>taterbennett</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4.0</th>\n",
       "      <td>When you can literally WORK towards your fitne...</td>\n",
       "      <td>2021-11-04 18:21:33+00:00</td>\n",
       "      <td>CB_Radio82</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 tweet  \\\n",
       "0.0  Orangetheory takes over the Komets game! #oran...   \n",
       "1.0  We are excited to announce the promotion of Fr...   \n",
       "2.0  The best Monday of 2021 is right around the \\r...   \n",
       "3.0  One month (only 9 workouts) with @orangetheory...   \n",
       "4.0  When you can literally WORK towards your fitne...   \n",
       "\n",
       "                      datetime      screenname  \n",
       "0.0  2021-11-06 01:08:16+00:00  KAILEYMSHERMAN  \n",
       "1.0  2021-11-05 14:09:09+00:00     KianCapital  \n",
       "2.0  2021-11-05 13:17:26+00:00  OTFKempsCorner  \n",
       "3.0  2021-11-05 02:12:11+00:00    taterbennett  \n",
       "4.0  2021-11-04 18:21:33+00:00      CB_Radio82  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check df head\n",
    "orangetheory_hash.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## @onepeloton Followers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make df of Peloton followers\n",
    "columns = [\"screen_name\", \"description\"]\n",
    "peloton_followers = pd.read_csv('onepeloton_followers.txt', names=columns, lineterminator='\\n')\n",
    "peloton_followers = peloton_followers.iloc[1: , :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(167340, 2)\n"
     ]
    }
   ],
   "source": [
    "# check df shape/size\n",
    "print(peloton_followers.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>screen_name</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>JoseRod45214209\\tMucha diversión\\r</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>krista_walter\\tEarly-stage CFO/IR Consultant</td>\n",
       "      <td>Analyst; Mentor @UNSWFounders &amp; Energylab; As...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>kdurkin11\\t\\r</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ChazeAbaq\\tmuniman\\r</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Drez2018\\tRetired ; Loving Life With Goms !!\\r</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      screen_name  \\\n",
       "1              JoseRod45214209\\tMucha diversión\\r   \n",
       "2    krista_walter\\tEarly-stage CFO/IR Consultant   \n",
       "3                                   kdurkin11\\t\\r   \n",
       "4                            ChazeAbaq\\tmuniman\\r   \n",
       "5  Drez2018\\tRetired ; Loving Life With Goms !!\\r   \n",
       "\n",
       "                                         description  \n",
       "1                                                NaN  \n",
       "2   Analyst; Mentor @UNSWFounders & Energylab; As...  \n",
       "3                                                NaN  \n",
       "4                                                NaN  \n",
       "5                                                NaN  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check df head\n",
    "peloton_followers.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## #onepeloton "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make df of peloton hashtags\n",
    "columns = [\"tweet\", \"datetime\", \"screenname\"]\n",
    "peloton_hash = pd.read_csv('peloton_hashtag.csv', names=columns, sep=',')\n",
    "peloton_hash = peloton_hash.iloc[1: , :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(756, 3)\n"
     ]
    }
   ],
   "source": [
    "# check df shape/size\n",
    "print(peloton_hash.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>datetime</th>\n",
       "      <th>screenname</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>#Peloton stock plunged up to 34% yesterday, it...</td>\n",
       "      <td>2021-11-06 15:32:00+00:00</td>\n",
       "      <td>TCollege</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>Wasn’t into working out at all. @tune2tunde ha...</td>\n",
       "      <td>2021-11-06 15:29:50+00:00</td>\n",
       "      <td>StrengthInTime</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.0</th>\n",
       "      <td>I’ve been slacking this week. Haven’t worked o...</td>\n",
       "      <td>2021-11-06 15:14:52+00:00</td>\n",
       "      <td>the17thman</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.0</th>\n",
       "      <td>New #Peloton item in the Apparel Store: Peloto...</td>\n",
       "      <td>2021-11-06 15:03:17+00:00</td>\n",
       "      <td>PelotonAlerts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4.0</th>\n",
       "      <td>Even on baecation we got to put in the work. #...</td>\n",
       "      <td>2021-11-06 15:03:01+00:00</td>\n",
       "      <td>idelle4life</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 tweet  \\\n",
       "0.0  #Peloton stock plunged up to 34% yesterday, it...   \n",
       "1.0  Wasn’t into working out at all. @tune2tunde ha...   \n",
       "2.0  I’ve been slacking this week. Haven’t worked o...   \n",
       "3.0  New #Peloton item in the Apparel Store: Peloto...   \n",
       "4.0  Even on baecation we got to put in the work. #...   \n",
       "\n",
       "                      datetime      screenname  \n",
       "0.0  2021-11-06 15:32:00+00:00        TCollege  \n",
       "1.0  2021-11-06 15:29:50+00:00  StrengthInTime  \n",
       "2.0  2021-11-06 15:14:52+00:00      the17thman  \n",
       "3.0  2021-11-06 15:03:17+00:00   PelotonAlerts  \n",
       "4.0  2021-11-06 15:03:01+00:00     idelle4life  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check df\n",
    "peloton_hash.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "orange_followers = open(\"orangetheory_followers.txt\",'r',  encoding=\"UTF-8\").read()\n",
    "pelo_followers = open(\"onepeloton_followers.txt\",'r',  encoding=\"UTF-8\").read()\n",
    "\n",
    "orange_hash = open(\"orangetheory_hashtag.csv\",'r',  encoding=\"UTF-8\").read()\n",
    "orange_hash_otf = open(\"otf_hashtag.csv\",'r',  encoding=\"UTF-8\").read()\n",
    "pelo_hash = open(\"peloton_hashtag.csv\",'r',  encoding=\"UTF-8\").read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "orangetheory followers stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Orangetheory followers is 3817792 tokens long.\n",
      "Orangetheory followers has 3575 unique tokens.\n",
      "Orangetheory followers lexical diversity is 0.001.\n",
      "Orangetheory followers average token length is 1.00.\n",
      "[(1, 3817792)]\n",
      "\n",
      "All statistics are calculated BEFORE normalization and tokenization.\n"
     ]
    }
   ],
   "source": [
    "print(f\"Orangetheory followers is {len(orange_followers)} tokens long.\")\n",
    "print(f\"Orangetheory followers has {len(set(orange_followers))} unique tokens.\")\n",
    "print(f\"Orangetheory followers lexical diversity is {len(set(orange_followers))/len(orange_followers):.3f}.\")\n",
    "# Build a vector of token length\n",
    "orange_followers_len = [len(w) for w in orange_followers]\n",
    "print(f\"Orangetheory followers average token length is {np.mean(orange_followers_len):.2f}.\")\n",
    "pprint(sorted(Counter(orange_followers_len).items()))\n",
    "\n",
    "\n",
    "print(\"\")\n",
    "print(\"All statistics are calculated BEFORE normalization and tokenization.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "onepeloton stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Onepeloton followers is 10490485 tokens long.\n",
      "Onepeloton followers has 4561 unique tokens.\n",
      "Onepeloton followers lexical diversity is 0.000.\n",
      "Onepeloton followers average token length is 1.00.\n",
      "[(1, 10490485)]\n",
      "\n",
      "All statistics are calculated BEFORE normalization and tokenization.\n"
     ]
    }
   ],
   "source": [
    "print(f\"Onepeloton followers is {len(pelo_followers)} tokens long.\")\n",
    "print(f\"Onepeloton followers has {len(set(pelo_followers))} unique tokens.\")\n",
    "print(f\"Onepeloton followers lexical diversity is {len(set(pelo_followers))/len(pelo_followers):.3f}.\")\n",
    "# Build a vector of token length\n",
    "pelo_followers_len = [len(w) for w in pelo_followers]\n",
    "print(f\"Onepeloton followers average token length is {np.mean(pelo_followers_len):.2f}.\")\n",
    "pprint(sorted(Counter(pelo_followers_len).items()))\n",
    "\n",
    "print(\"\")\n",
    "print(\"All statistics are calculated BEFORE normalization and tokenization.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#orangethoery stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#orangetheory is 4828 tokens long.\n",
      "#orangetheory has 100 unique tokens.\n",
      "#orangetheory lexical diversity is 0.021.\n",
      "#orangetheory average token length is 1.00.\n",
      "[(1, 4828)]\n",
      "\n",
      "All statistics are calculated BEFORE normalization and tokenization.\n"
     ]
    }
   ],
   "source": [
    "print(f\"#orangetheory is {len(orange_hash)} tokens long.\")\n",
    "print(f\"#orangetheory has {len(set(orange_hash))} unique tokens.\")\n",
    "print(f\"#orangetheory lexical diversity is {len(set(orange_hash))/len(orange_hash):.3f}.\")\n",
    "# Build a vector of token length\n",
    "orange_hash_len = [len(w) for w in orange_hash]\n",
    "print(f\"#orangetheory average token length is {np.mean(orange_hash_len):.2f}.\")\n",
    "pprint(sorted(Counter(orange_hash_len).items()))\n",
    "\n",
    "print(\"\")\n",
    "print(\"All statistics are calculated BEFORE normalization and tokenization.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#otf stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#otf is 47994 tokens long.\n",
      "#otf has 176 unique tokens.\n",
      "#otf lexical diversity is 0.004.\n",
      "#otf average token length is 1.00.\n",
      "[(1, 47994)]\n",
      "\n",
      "All statistics are calculated BEFORE normalization and tokenization.\n"
     ]
    }
   ],
   "source": [
    "print(f\"#otf is {len(orange_hash_otf)} tokens long.\")\n",
    "print(f\"#otf has {len(set(orange_hash_otf))} unique tokens.\")\n",
    "print(f\"#otf lexical diversity is {len(set(orange_hash_otf))/len(orange_hash_otf):.3f}.\")\n",
    "# Build a vector of token length\n",
    "orange_hash_otf_len = [len(w) for w in orange_hash_otf]\n",
    "print(f\"#otf average token length is {np.mean(orange_hash_otf_len):.2f}.\")\n",
    "pprint(sorted(Counter(orange_hash_otf_len).items()))\n",
    "\n",
    "print(\"\")\n",
    "print(\"All statistics are calculated BEFORE normalization and tokenization.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#peloton "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#peloton is 157475 tokens long.\n",
      "#peloton has 226 unique tokens.\n",
      "#peloton lexical diversity is 0.001.\n",
      "#peloton average token length is 1.00.\n",
      "[(1, 157475)]\n",
      "\n",
      "All statistics are calculated BEFORE normalization and tokenization.\n"
     ]
    }
   ],
   "source": [
    "print(f\"#peloton is {len(pelo_hash)} tokens long.\")\n",
    "print(f\"#peloton has {len(set(pelo_hash))} unique tokens.\")\n",
    "print(f\"#peloton lexical diversity is {len(set(pelo_hash))/len(pelo_hash):.3f}.\")\n",
    "# Build a vector of token length\n",
    "pelo_hash_len = [len(w) for w in pelo_hash]\n",
    "print(f\"#peloton average token length is {np.mean(pelo_hash_len):.2f}.\")\n",
    "pprint(sorted(Counter(pelo_hash_len).items()))\n",
    "\n",
    "print(\"\")\n",
    "print(\"All statistics are calculated BEFORE normalization and tokenization.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
